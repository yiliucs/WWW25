import torch
import torch.nn as nn

class DivLoss(nn.Module):
    """
    Diversity loss for improving the performance.
    """

    def __init__(self):
        """
        Class initializer.
        """
        super().__init__()

    def forward2(self, noises, layer):
        """
        Forward propagation.
        """
        if len(layer.shape) > 2:
            layer = layer.view((layer.size(0), -1))
        chunk_size = layer.size(0) // 2

        ####### diversity loss ########
        eps1, eps2=torch.split(noises, chunk_size, dim=0)
        chunk1, chunk2=torch.split(layer, chunk_size, dim=0)
        lz=torch.mean(torch.abs(chunk1 - chunk2)) / torch.mean(
            torch.abs(eps1 - eps2))
        eps=1 * 1e-5
        diversity_loss=1 / (lz + eps)
        return diversity_loss

    def forward(self, noises, layer):
        """
        Forward propagation.
        """
        if len(layer.shape) > 2:
            layer=layer.view((layer.size(0), -1))
        chunk_size=layer.size(0) // 2

        ####### diversity loss ########
        eps1, eps2=torch.split(noises, chunk_size, dim=0)
        chunk1, chunk2=torch.split(layer, chunk_size, dim=0)
        lz=torch.mean(torch.abs(chunk1 - chunk2)) / torch.mean(
            torch.abs(eps1 - eps2))
        eps=1 * 1e-5
        diversity_loss=1 / (lz + eps)
        return diversity_loss


class DiversityLoss(nn.Module):
    """
    Diversity loss for improving the performance.
    """
    def __init__(self, metric):
        """
        Class initializer.
        """
        super().__init__()
        self.metric = metric
        self.cosine = nn.CosineSimilarity(dim=2)

    def compute_distance(self, tensor1, tensor2, metric):
        """
        Compute the distance between two tensors.
        """
        if metric == 'l1':
            return torch.abs(tensor1 - tensor2).mean(dim=(2,))
        elif metric == 'l2':
            return torch.pow(tensor1 - tensor2, 2).mean(dim=(2,))
        elif metric == 'cosine':
            return 1 - self.cosine(tensor1, tensor2)
        else:
            raise ValueError(metric)

    def pairwise_distance(self, tensor, how):
        """
        Compute the pairwise distances between a Tensor's rows.
        """
        n_data = tensor.size(0)
        tensor1 = tensor.expand((n_data, n_data, tensor.size(1)))
        tensor2 = tensor.unsqueeze(dim=1)
        return self.compute_distance(tensor1, tensor2, how)

    def forward(self, noises, layer):
        """
        Forward propagation.
        """
        if len(layer.shape) > 2:
            layer = layer.view((layer.size(0), -1))
        layer_dist = self.pairwise_distance(layer, how=self.metric)
        noise_dist = self.pairwise_distance(noises, how='l2')
        return torch.exp(torch.mean(-noise_dist * layer_dist))

class Generator(nn.Module):
    def __init__(self,  modality,opt,input_dim=64, embedding=False, latent_layer_idx=-1):
        super(Generator, self).__init__()
        self.embedding = embedding
        #self.model=
        self.opt=opt
        self.latent_layer_idx = latent_layer_idx
        self.modality =modality

        self.hidden_dim, self.latent_dim, self.input_channel, self.n_class, self.noise_dim = 976, 488, 1, 64, 64
        self.fc_configs = [input_dim*2, self.hidden_dim]
        self.init_loss_fn()
        self.build_network()

    def get_number_of_parameters(self):
        pytorch_total_params=sum(p.numel() for p in self.parameters() if p.requires_grad)
        return pytorch_total_params

    def init_loss_fn(self):
        self.crossentropy_loss=nn.NLLLoss(reduce=False) # same as above
        self.diversity_loss = DiversityLoss(metric='l1')
        self.dist_loss = nn.MSELoss()

    def build_network(self):
        if self.embedding:
            self.embedding_layer = nn.Embedding(self.n_class, self.noise_dim)
        ### FC modules ####
        self.fc_layers = nn.ModuleList()
        for i in range(len(self.fc_configs) - 1):
            input_dim, out_dim = self.fc_configs[i], self.fc_configs[i + 1]
            fc = nn.Linear(input_dim, out_dim)
            bn = nn.BatchNorm1d(out_dim)
            act = nn.ReLU()
            self.fc_layers += [fc, bn, act]
        ### Representation layer
        self.representation_layer = nn.Linear(self.fc_configs[-1], self.latent_dim)
        # print("Build last layer {} X {}".format(self.fc_configs[-1], self.latent_dim))

    def forward(self, labels, latent_layer_idx=-1, verbose=True):
        """
        G(Z|y) or G(X|y):
        Generate either latent representation( latent_layer_idx < 0) or raw image (latent_layer_idx=0) conditional on labels.
        :param labels:
        :param latent_layer_idx:
            if -1, generate latent representation of the last layer,
            -2 for the 2nd to last layer, 0 for raw images.
        :param verbose: also return the sampled Gaussian noise if verbose = True
        :return: a dictionary of output information.
        """
        labels.cuda(self.opt.cuda_device)
        # print(labels)
        result = {}
        batch_size = labels.shape[0]
        eps = torch.rand((batch_size, self.noise_dim)).cuda(self.opt.cuda_device)# sampling from Gaussian
        if verbose:
            result['eps'] = eps
        if self.embedding: # embedded dense vector
            y_input = self.embedding_layer(labels).cuda(self.opt.cuda_device)
        else: # one-hot (sparse) vector
            y_input = torch.FloatTensor(batch_size, self.n_class).cuda(self.opt.cuda_device)
            y_input.zero_()
            #labels = labels.view
            y_input.scatter_(1, labels.view(-1,1), 1)
            # print(y_input)

        z = torch.cat((eps, y_input), dim=1)
        ### FC layers
        for layer in self.fc_layers:
            z = layer(z)
            # print(z.shape)
        z = self.representation_layer(z)
        result['output'] = z
        return result
# ## gps input: [bsz, 2, 1]
# class gps_encoder(nn.Module):

#     def __init__(self):
#         super().__init__()

#         self.layer1 = nn.Sequential(
#         nn.Conv1d(2, 20, 2, padding = 'same'),
#         nn.ReLU(inplace=True)
#         )

#         self.layer2 = nn.Sequential(
#         nn.Conv1d(20, 40, 2, padding = 'same'),
#         nn.ReLU(inplace=True),
#         nn.MaxPool1d(2,padding = 1)
#         )

#         self.layer3 = nn.Sequential(
#         nn.Conv1d(40, 80, 2, padding = 'same'),
#         nn.ReLU(inplace=True)
#         )

#         self.layer4 = nn.Sequential(
#         nn.Conv1d(80, 40, 2, padding = 'same'),
#         nn.ReLU(inplace=True),
#         nn.MaxPool1d(2,padding = 1),
#         nn.Flatten()
#         )

#     def forward(self, x):
#         x = self.layer1(x)
#         x = self.layer2(x)
#         x = self.layer3(x)
#         x = self.layer4(x)

#         return x


## gps input: [bsz, 2, 1]
class gps_encoder(nn.Module):

    def __init__(self):
        super().__init__()

        self.layer1 = nn.Sequential(
            nn.Conv1d(2, 20, 3, padding=1),
            nn.ReLU(inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.Conv1d(20, 40, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(2, padding=1)
        )

        self.layer3 = nn.Sequential(
            nn.Conv1d(40, 80, 3, padding=1),
            nn.ReLU(inplace=True)
        )

        self.layer4 = nn.Sequential(
            nn.Conv1d(80, 40, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(2, padding=1),
            nn.Flatten()
        )

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        return x


## lidar input: [bsz, 20, 20, 20]
class lidar_encoder(nn.Module):
    def __init__(self):
        super().__init__()

        self.channel = 32
        self.dropProb = 0.3

        self.layer1 = nn.Sequential(
            nn.Conv2d(20, 32, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

            nn.Conv2d(128, 32, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True)

        )

        self.maxpool = nn.Sequential(
            nn.MaxPool2d(kernel_size=(2, 3)),
            nn.Dropout(p=self.dropProb)
        )

        self.maxpool_ = nn.Sequential(
            nn.MaxPool2d(kernel_size=(1, 2)),
            nn.Dropout(p=self.dropProb)
        )

        self.flatten_layer = nn.Sequential(
            nn.Flatten()
        )

    def forward(self, x):
        a = self.layer1(x)
        x = a + self.layer2(a)
        x = self.maxpool(x)  # b

        b = x
        x = self.layer2(x) + b
        x = self.maxpool(x)  # c

        c = x
        x = self.layer2(x) + c
        x = self.maxpool_(x)  # d

        d = x
        x = self.layer2(x) + d

        x = self.flatten_layer(x)

        return x


## image input: [bsz, 3, 112, 112]
class image_encoder(nn.Module):
    def __init__(self):
        super().__init__()

        self.channel = 32
        self.dropProb = 0.25

        self.layer0 = nn.Sequential(
            nn.Conv2d(3, self.channel, kernel_size=(7, 7), padding=(1, 1)),
            nn.ReLU(inplace=True)
        )

        self.layer1 = nn.Sequential(
            nn.Conv2d(self.channel, 32, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

            nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

            nn.Conv2d(64, 32, kernel_size=(3, 3), padding=(1, 1)),
            nn.ReLU(inplace=True),

        )

        self.maxpool = nn.Sequential(
            nn.MaxPool2d(kernel_size=(6, 6)),
            nn.Dropout(p=self.dropProb)
        )

        self.maxpool_ = nn.Sequential(
            nn.MaxPool2d(kernel_size=(6, 6)),
            nn.Dropout(p=self.dropProb),
            nn.Flatten()
        )

    def forward(self, x):
        x = self.layer0(x)
        x = self.layer1(x)
        b = x
        x = self.layer2(x) + b
        x = self.maxpool(x)
        c = x
        x = self.layer2(x) + c
        x = self.maxpool_(x)

        return x


class MySingleModel(nn.Module):

    def __init__(self, num_classes, modality):
        super().__init__()

        # print("DEBUG: modality is: ", modality)

        if modality == 'lidar':
            self.encoder = lidar_encoder()
            self.classifier = nn.Sequential(
                nn.Linear(160, num_classes),
                nn.Softmax()
            )
        elif modality == 'image':
            self.encoder = image_encoder()
            self.classifier = nn.Sequential(
                nn.Linear(288, num_classes),
                nn.Softmax()
            )
        elif modality == 'gps':
            self.encoder = gps_encoder()
            self.classifier = nn.Sequential(
                nn.Linear(40, num_classes),
                nn.Softmax()
            )

    def forward(self, x):
        # print(x.shape)
        feature = self.encoder(x)
        output = self.classifier(feature)

        return output


class Encoder2_1(nn.Module):
    def __init__(self):
        super().__init__()

        self.encoder_1 = gps_encoder()
        self.encoder_2 = lidar_encoder()

    def forward(self, x1, x2):
        feature_1 = self.encoder_1(x1)
        feature_2 = self.encoder_2(x2)

        return feature_1, feature_2


class Encoder2_2(nn.Module):
    def __init__(self):
        super().__init__()

        self.encoder_1 = gps_encoder()
        self.encoder_2 = image_encoder()

    def forward(self, x1, x2):
        feature_1 = self.encoder_1(x1)
        feature_2 = self.encoder_2(x2)

        return feature_1, feature_2


class Encoder2_3(nn.Module):
    def __init__(self):
        super().__init__()

        self.encoder_1 = lidar_encoder()
        self.encoder_2 = image_encoder()

    def forward(self, x1, x2):
        feature_1 = self.encoder_1(x1)
        feature_2 = self.encoder_2(x2)

        return feature_1, feature_2


class My2Model(nn.Module):

    def __init__(self, num_classes, modality):
        super().__init__()

        # print("DEBUG: modality is: ", modality)

        if modality == 'g+l':
            self.encoder = Encoder2_1()
            self.classifier = nn.Sequential(
                nn.Linear(200, num_classes),
                nn.Softmax()
            )

        elif modality == 'g+i':
            self.encoder = Encoder2_2()
            self.classifier = nn.Sequential(
                nn.Linear(328, num_classes),
                nn.Softmax()
            )

        elif modality == 'l+i':
            self.encoder = Encoder2_3()
            self.classifier = nn.Sequential(
                nn.Linear(448, num_classes),
                nn.Softmax()
            )

    def forward(self, x1, x2):
        # print(x.shape)

        feature_1, feature_2 = self.encoder(x1, x2)

        feature = torch.cat((feature_1, feature_2), dim=1)
        output = self.classifier(feature)

        return output


class Encoder3(nn.Module):
    def __init__(self):
        super().__init__()

        self.encoder_1 = gps_encoder()
        self.encoder_2 = lidar_encoder()
        self.encoder_3 = image_encoder()

    def forward(self, x1, x2, x3):
        feature_1 = self.encoder_1(x1)
        feature_2 = self.encoder_2(x2)
        feature_3 = self.encoder_3(x3)

        return feature_1, feature_2, feature_3


class My3Model(nn.Module):

    def __init__(self, num_classes,miss_modal,miss_rate):
        super().__init__()
        self.miss_modal=miss_modal
        self.miss_rate=miss_rate
        self.encoder = Encoder3()
        self.modality='all'
        self.classifier = nn.Sequential(
            nn.Linear(488, num_classes),
            nn.Softmax()
        )

    def forward(self, x1, x2, x3,latent=False):
        if latent:
            feature=x1
        else:

            feature_1, feature_2, feature_3 = self.encoder(x1, x2, x3)

            feature = torch.cat((feature_1, feature_2, feature_3), dim=1)
        # feature_1, feature_2, feature_3 = self.encoder(x1, x2, x3)
        # # print(feature_1.shape)
        # # print(feature_2.shape)
        # # print(feature_3.shape)
        # feature = torch.cat((feature_1, feature_2, feature_3), dim=1)
        output = self.classifier(feature)

        return output,feature
